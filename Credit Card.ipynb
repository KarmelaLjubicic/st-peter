{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import hashlib, time, operator, functools, itertools\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, recall_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, Imputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (7000, 24)\n",
      "Default rate:\n",
      " 0    5441\n",
      "1    1559\n",
      "Name: default.payment.next.month, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.136720</td>\n",
       "      <td>0.810161</td>\n",
       "      <td>0.185828</td>\n",
       "      <td>-1.057295</td>\n",
       "      <td>-1.246020</td>\n",
       "      <td>1.794564</td>\n",
       "      <td>1.782348</td>\n",
       "      <td>-0.696663</td>\n",
       "      <td>-0.666599</td>\n",
       "      <td>-1.530046</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.672497</td>\n",
       "      <td>-0.663059</td>\n",
       "      <td>-0.652724</td>\n",
       "      <td>-0.341942</td>\n",
       "      <td>-0.227086</td>\n",
       "      <td>-0.296801</td>\n",
       "      <td>-0.308063</td>\n",
       "      <td>-0.314136</td>\n",
       "      <td>-0.293382</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.365981</td>\n",
       "      <td>0.810161</td>\n",
       "      <td>0.185828</td>\n",
       "      <td>0.858557</td>\n",
       "      <td>-1.029047</td>\n",
       "      <td>-0.874991</td>\n",
       "      <td>1.782348</td>\n",
       "      <td>0.138865</td>\n",
       "      <td>0.188746</td>\n",
       "      <td>0.234917</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.621636</td>\n",
       "      <td>-0.606229</td>\n",
       "      <td>-0.597966</td>\n",
       "      <td>-0.341942</td>\n",
       "      <td>-0.213588</td>\n",
       "      <td>-0.240005</td>\n",
       "      <td>-0.244230</td>\n",
       "      <td>-0.314136</td>\n",
       "      <td>-0.180878</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.597202</td>\n",
       "      <td>0.810161</td>\n",
       "      <td>0.185828</td>\n",
       "      <td>0.858557</td>\n",
       "      <td>-0.161156</td>\n",
       "      <td>0.014861</td>\n",
       "      <td>0.111736</td>\n",
       "      <td>0.138865</td>\n",
       "      <td>0.188746</td>\n",
       "      <td>0.234917</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.449730</td>\n",
       "      <td>-0.417188</td>\n",
       "      <td>-0.391630</td>\n",
       "      <td>-0.250292</td>\n",
       "      <td>-0.191887</td>\n",
       "      <td>-0.240005</td>\n",
       "      <td>-0.244230</td>\n",
       "      <td>-0.248683</td>\n",
       "      <td>-0.012122</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.905498</td>\n",
       "      <td>0.810161</td>\n",
       "      <td>0.185828</td>\n",
       "      <td>-1.057295</td>\n",
       "      <td>0.164303</td>\n",
       "      <td>0.014861</td>\n",
       "      <td>0.111736</td>\n",
       "      <td>0.138865</td>\n",
       "      <td>0.188746</td>\n",
       "      <td>0.234917</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232373</td>\n",
       "      <td>-0.186729</td>\n",
       "      <td>-0.156579</td>\n",
       "      <td>-0.221191</td>\n",
       "      <td>-0.169361</td>\n",
       "      <td>-0.228645</td>\n",
       "      <td>-0.237846</td>\n",
       "      <td>-0.244166</td>\n",
       "      <td>-0.237130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.905498</td>\n",
       "      <td>-1.234323</td>\n",
       "      <td>0.185828</td>\n",
       "      <td>-1.057295</td>\n",
       "      <td>2.334029</td>\n",
       "      <td>-0.874991</td>\n",
       "      <td>0.111736</td>\n",
       "      <td>-0.696663</td>\n",
       "      <td>0.188746</td>\n",
       "      <td>0.234917</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.346997</td>\n",
       "      <td>-0.348137</td>\n",
       "      <td>-0.331482</td>\n",
       "      <td>-0.221191</td>\n",
       "      <td>1.335034</td>\n",
       "      <td>0.271165</td>\n",
       "      <td>0.266434</td>\n",
       "      <td>-0.269039</td>\n",
       "      <td>-0.255187</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL       SEX  EDUCATION  MARRIAGE       AGE     PAY_0     PAY_2  \\\n",
       "0  -1.136720  0.810161   0.185828 -1.057295 -1.246020  1.794564  1.782348   \n",
       "1  -0.365981  0.810161   0.185828  0.858557 -1.029047 -0.874991  1.782348   \n",
       "2  -0.597202  0.810161   0.185828  0.858557 -0.161156  0.014861  0.111736   \n",
       "3  -0.905498  0.810161   0.185828 -1.057295  0.164303  0.014861  0.111736   \n",
       "4  -0.905498 -1.234323   0.185828 -1.057295  2.334029 -0.874991  0.111736   \n",
       "\n",
       "      PAY_3     PAY_4     PAY_5             ...              BILL_AMT4  \\\n",
       "0 -0.696663 -0.666599 -1.530046             ...              -0.672497   \n",
       "1  0.138865  0.188746  0.234917             ...              -0.621636   \n",
       "2  0.138865  0.188746  0.234917             ...              -0.449730   \n",
       "3  0.138865  0.188746  0.234917             ...              -0.232373   \n",
       "4 -0.696663  0.188746  0.234917             ...              -0.346997   \n",
       "\n",
       "   BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  \\\n",
       "0  -0.663059  -0.652724 -0.341942 -0.227086 -0.296801 -0.308063 -0.314136   \n",
       "1  -0.606229  -0.597966 -0.341942 -0.213588 -0.240005 -0.244230 -0.314136   \n",
       "2  -0.417188  -0.391630 -0.250292 -0.191887 -0.240005 -0.244230 -0.248683   \n",
       "3  -0.186729  -0.156579 -0.221191 -0.169361 -0.228645 -0.237846 -0.244166   \n",
       "4  -0.348137  -0.331482 -0.221191  1.335034  0.271165  0.266434 -0.269039   \n",
       "\n",
       "   PAY_AMT6  default.payment.next.month  \n",
       "0 -0.293382                           1  \n",
       "1 -0.180878                           1  \n",
       "2 -0.012122                           0  \n",
       "3 -0.237130                           0  \n",
       "4 -0.255187                           0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def credit_dataset():\n",
    "    dataset = pd.read_csv(\"data\\\\UCI_Credit_Card.csv\")\n",
    "    del dataset['ID']\n",
    "\n",
    "    need_scaling = list(filter(functools.partial(operator.ne, 'default.payment.next.month'), dataset.columns.tolist()))\n",
    "    scaler = StandardScaler()\n",
    "    for feature in need_scaling:\n",
    "        dataset[feature] = scaler.fit_transform(dataset[feature].values.reshape(-1,1))\n",
    "            \n",
    "    return dataset\n",
    "\n",
    "dataset = credit_dataset()[:7000]\n",
    "print(\"Dataset shape:\", dataset.shape)\n",
    "print(\"Default rate:\\n\", dataset[\"default.payment.next.month\"].value_counts())\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset_good shape: (5441, 23)\n",
      "Dataset_bad shape: (1559, 23)\n"
     ]
    }
   ],
   "source": [
    "dataset_good = dataset[dataset['default.payment.next.month'] == 0]\n",
    "dataset_bad = dataset[dataset['default.payment.next.month'] == 1]\n",
    "del dataset_good['default.payment.next.month']\n",
    "del dataset_bad['default.payment.next.month']\n",
    "print(\"Dataset_good shape:\", dataset_good.shape)\n",
    "print(\"Dataset_bad shape:\", dataset_bad.shape)\n",
    "\n",
    "#good_rate = 23364/30000\n",
    "#bad_rate = 6636/30000\n",
    "#good_rate = 1566/2000\n",
    "#bad_rate = 434/2000\n",
    "#print(\"Non-default rate:\", good_rate)\n",
    "#print(\"Default rate:\", bad_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratificirana podjela - provjera koliko je potrebno \"dobrih\" i \"loših\" primjera u train i test setu. Sampliranje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dimensions for symmetric classifier:\n",
      "(4352, 23) (1089, 23) (1247, 23) (312, 23)\n",
      "\n",
      "Dimensions for base classifier:\n",
      "(5599, 23) (5599, 1) (1401, 23) (1401, 1)\n"
     ]
    }
   ],
   "source": [
    "good_train, good_test = train_test_split(dataset_good, test_size=0.2)\n",
    "bad_train, bad_test = train_test_split(dataset_bad, test_size=0.2)\n",
    "print(\"\\nDimensions for symmetric classifier:\")\n",
    "print(good_train.shape, good_test.shape, bad_train.shape, bad_test.shape)\n",
    "\n",
    "y_train = np.array([1]*len(good_train) + [0]*len(bad_train)).reshape(-1,1)\n",
    "x_train = good_train.append(bad_train)\n",
    "x_train['default.payment.next.month'] = y_train\n",
    "x_train = shuffle(x_train)\n",
    "y_train = x_train['default.payment.next.month'].reshape(-1,1)\n",
    "del x_train['default.payment.next.month']\n",
    "\n",
    "y_test = np.array([1]*len(good_test) + [0]*len(bad_test)).reshape(-1,1)\n",
    "x_test = good_test.append(bad_test)\n",
    "x_test['default.payment.next.month'] = y_test\n",
    "x_test = shuffle(x_test)\n",
    "y_test = x_test['default.payment.next.month'].reshape(-1,1)\n",
    "del x_test['default.payment.next.month']\n",
    "\n",
    "print(\"\\nDimensions for base classifier:\")\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def small_network(input_placeholder, keep_prob):\n",
    "    #regularizer = tf.contrib.layers.l2_regularizer(scale=0.1)\n",
    "    #kernel_regularizer = regularizer\n",
    "    #layer_1 = tf.layers.dense(input_placeholder, 70, tf.nn.relu, name=\"layer_1\", reuse=tf.AUTO_REUSE)\n",
    "    #drop_out = tf.nn.dropout(layer_1, keep_prob)\n",
    "                             #kernel_regularizer = regularizer)\n",
    "    #layer_2 = tf.layers.dense(layer_1, 60, tf.nn.relu, name=\"layer_2\", reuse=tf.AUTO_REUSE)\n",
    "    #drop_out2 = tf.nn.dropout(layer_2, keep_prob)\n",
    "                             #kernel_regularizer = regularizer)\n",
    "    #layer_3 = tf.layers.dense(layer_2, 40, tf.nn.relu, name=\"layer_3\", reuse=tf.AUTO_REUSE)#,\n",
    "                              #kernel_regularizer = regularizer)\n",
    "    #drop_out3 = tf.nn.dropout(layer_3, keep_prob)\n",
    "                             \n",
    "    layer_4 = tf.layers.dense(input_placeholder, 10, tf.nn.relu, name=\"layer_4\", reuse=tf.AUTO_REUSE)#,\n",
    "                             #kernel_regularizer = regularizer)\n",
    "    #drop_out4 = tf.nn.dropout(layer_4, keep_prob)\n",
    "    layer_5 = tf.layers.dense(layer_4, 5, tf.nn.relu, name=\"layer_5\", reuse=tf.AUTO_REUSE)#,\n",
    "                             #kernel_regularizer = regularizer)\n",
    "    #drop_out5 = tf.nn.dropout(layer_5, keep_prob)\n",
    "    output = tf.layers.dense(layer_5, 1, name=\"output\", reuse=tf.AUTO_REUSE)#,\n",
    "                            #kernel_regularizer = regularizer)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_base(y_true, y_score):\n",
    "    print(\"Number of 0.5 predictions = \", y_score.count(0.5))\n",
    "    somers_d_score(y_true, y_score, True)\n",
    "    y_score = [1 if o >= 0.5 else 0 for o in y_score]\n",
    "    conf_matrix(y_true, y_score)\n",
    "    print('Accuracy score = ', accuracy_score(y_true, y_score))\n",
    "    print('Recall score = ', recall_score(y_true, y_score))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def somers_d_score(y_true, y_score, base):\n",
    "    if base:\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "        auc_score = auc(fpr, tpr)\n",
    "        print('Somers\\' D score = ', 2 * auc_score - 1)\n",
    "    else:\n",
    "        for o in y_score:\n",
    "            if o > 0.5:\n",
    "                o = 1\n",
    "            else:\n",
    "                if o == 0.5:\n",
    "                    o = 0\n",
    "                else:\n",
    "                    o = -1\n",
    "        print('Somers\\' D score = ', sum(y_score)/len(y_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_matrix(y, y_score):\n",
    "    y_score = [1 if o >= 0.5 else 0 for o in y_score]\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_score).ravel()\n",
    "    print(\"True negative = \", tn, \", False positive = \", fp, \", False negative = \", fn, \"True positive = \", tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrcv_hashmap = {}\n",
    "clf = LogisticRegressionCV(cv = 5).fit(x_train, y_train)\n",
    "h = clf.predict_proba(x_test)[:,1].tolist()\n",
    "y_score = clf.predict(x_test)\n",
    "\n",
    "for i in range(len(x_test)):\n",
    "    x = x_test.iloc[i,:]\n",
    "    key = hashlib.sha256(x.values.tobytes()).hexdigest()\n",
    "    lrcv_hashmap[key] = tuple((x, y_score[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0.5 predictions =  0\n",
      "Somers' D score =  0.37233641779096316\n",
      "True negative =  67 , False positive =  245 , False negative =  43 True positive =  1046\n",
      "Accuracy score =  0.7944325481798715\n",
      "Recall score =  0.960514233241506\n"
     ]
    }
   ],
   "source": [
    "metrics_base(y_test, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "input_ = tf.placeholder(tf.float32, shape=[None, x_train.shape[1]])\n",
    "output = tf.placeholder(tf.float32, shape=[None,1])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "logit = small_network(input_, keep_prob)\n",
    "h = tf.sigmoid(logit)\n",
    "\n",
    "loss = tf.losses.sigmoid_cross_entropy(output, logit) #+ tf.losses.get_regularization_loss()\n",
    "lr = tf.placeholder(tf.float32, shape=[])\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=lr, beta1=0.9, beta2=0.999).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_hashmap = {}\n",
    "\n",
    "def base_classification(data, y, l_r, num_epochs, bsize, if_test):\n",
    "    num_batches = len(data) // bsize\n",
    "    residue = len(data) % bsize\n",
    "    if residue != 0:\n",
    "        num_batches += 1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        h_out = []\n",
    "\n",
    "        for batch in range(num_batches):\n",
    "            i = batch * bsize\n",
    "            j = (batch + 1) * bsize\n",
    "            if(residue != 0 and batch + 1 == num_batches):\n",
    "                j = i + residue\n",
    "\n",
    "            loss_, h_, _ = sess.run([loss, h, train_op],feed_dict={input_: data.iloc[i:j,:],output: y[i:j],lr:l_r, keep_prob:0.5})\n",
    "            h_out.extend([hh[0] for hh in h_])\n",
    "            total_loss += loss_\n",
    "            \n",
    "            if(if_test):\n",
    "                for k in range(i,j):\n",
    "                    x = data.iloc[k,:]\n",
    "                    key = hashlib.sha256(x.values.tobytes()).hexdigest()\n",
    "                    base_hashmap[key] = tuple((x, round(h_out[k])))\n",
    "\n",
    "        #print(\"Epoch {} / {}, Loss = {}\".format(epoch + 1, num_epochs, total_loss / num_batches))\n",
    "        \n",
    "    return h_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Number of 0.5 predictions =  0\n",
      "Somers' D score =  0.5851799834308222\n",
      "True negative =  465 , False positive =  782 , False negative =  236 True positive =  4116\n",
      "Accuracy score =  0.8181818181818182\n",
      "Recall score =  0.9457720588235294\n",
      "\n",
      "Testing...\n",
      "Number of 0.5 predictions =  0\n",
      "Somers' D score =  0.5112753408207951\n",
      "True negative =  119 , False positive =  193 , False negative =  91 True positive =  998\n",
      "Accuracy score =  0.7972876516773733\n",
      "Recall score =  0.9164370982552801\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    base_train_out = base_classification(x_train, y_train, 0.01, 100, 50, False)\n",
    "    metrics_base(y_train, base_train_out)\n",
    "    \n",
    "    print(\"\\nTesting...\")\n",
    "    base_test_out = base_classification(x_test, y_test, 0.01, 1, 50, True) \n",
    "    metrics_base(y_test, base_test_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symmetric classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "num_features = good_train.shape[1]\n",
    "\n",
    "input_left = tf.placeholder(tf.float32, shape=[None, num_features*2])\n",
    "input_right = tf.concat([input_left[:, num_features:], input_left[:, :num_features]], axis=1)\n",
    "output = tf.placeholder(tf.float32, shape=[None,1])\n",
    "\n",
    "f_left = small_network(input_left, 0.5)\n",
    "f_right = small_network(input_right, 0.5)\n",
    "logit = f_left - f_right\n",
    "\n",
    "h = tf.sigmoid(logit)\n",
    "\n",
    "loss = tf.losses.sigmoid_cross_entropy(output, logit)\n",
    "lr = tf.placeholder(tf.float32, shape=[])\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=lr, beta1=0.9, beta2=0.999).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "symm_hashmap = {}\n",
    "\n",
    "def symmetric_classification(good_data, bad_data, l_r, num_epochs, if_test):\n",
    "    y = np.empty((len(bad_data) * len(good_data), 1), int)\n",
    "    y.fill(1)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        good_data = shuffle(good_data)\n",
    "        bad_data = shuffle(bad_data)\n",
    "        h_out = []        \n",
    "        conc = np.concatenate\n",
    "            \n",
    "        for i in range(len(good_data)):\n",
    "            \n",
    "            minibatch = []\n",
    "            append = minibatch.append\n",
    "            y_ = np.empty((len(bad_data), 1), int)\n",
    "            y_.fill(1.)\n",
    "            \n",
    "            g = good_data.iloc[i,:].reshape(1,-1)\n",
    "            \n",
    "            for j in range(len(bad_data)):\n",
    "                b = bad_data.iloc[j,:].reshape(1,-1)\n",
    "                append(conc((g, b), axis=None))\n",
    "            \n",
    "                if(if_test):\n",
    "                    hash_good = hashlib.sha256(g.tobytes()).hexdigest()\n",
    "                    hash_bad = hashlib.sha256(b.tobytes()).hexdigest()\n",
    "                    key = tuple((hash_good, hash_bad))\n",
    "                    symm_hashmap[key] = 1\n",
    "            \n",
    "            loss_, h_, _ = sess.run([loss, h, train_op], feed_dict={input_left: minibatch, output: y_, lr: l_r})\n",
    "            h_out.extend([hh[0] for hh in h_])\n",
    "            total_loss += loss_\n",
    "\n",
    "        print(\"Epoch {} / {}, Loss = {}\".format(epoch + 1, num_epochs, total_loss / len(bad_data)))\n",
    "        \n",
    "    return h_out, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 1 / 1, Loss = 1.8782323333826858\n",
      "Somers' D score =  0.6401894302176013\n",
      "True negative =  0 , False positive =  0 , False negative =  1498772 True positive =  3928172\n",
      "\n",
      "Testing...\n",
      "Epoch 1 / 1, Loss = 1.7265620100683567\n",
      "Somers' D score =  0.6742185583816181\n",
      "True negative =  0 , False positive =  0 , False negative =  78980 True positive =  260788\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    symm_train_out, y = symmetric_classification(good_train, bad_train, 0.001, 1, False)\n",
    "    somers_d_score(y, symm_train_out, False)\n",
    "    conf_matrix(y, symm_train_out)\n",
    "    \n",
    "    print(\"\\nTesting...\")\n",
    "    symm_test_out, y = symmetric_classification(good_test, bad_test, 0.001, 1, True)\n",
    "    somers_d_score(y, symm_test_out, False)\n",
    "    conf_matrix(y, symm_test_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base & symmetric classification comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukupno preklapanje u procjenama base i symmetric klasifikatora je:  0.3495385086294177\n",
      "Ukupno preklapanje u procjenama log.reg. CV i symmetric klasifikatora je:  0.20626427444609263\n"
     ]
    }
   ],
   "source": [
    "N = len(good_test) * len(bad_test)\n",
    "a = 0\n",
    "b = 0\n",
    "\n",
    "for i in range(len(good_test)):\n",
    "    for j in range(len(bad_test)):\n",
    "        hash_good = hashlib.sha256(good_test.iloc[i,:].values.tobytes()).hexdigest()\n",
    "        hash_bad = hashlib.sha256(bad_test.iloc[j,:].values.tobytes()).hexdigest()\n",
    "        key = (hash_good, hash_bad)\n",
    "        if((base_hashmap[hash_good][1] == 1 and base_hashmap[hash_bad][1] == 0 and symm_hashmap[key] == 1)\n",
    "          or (base_hashmap[hash_good][1] == 0 and base_hashmap[hash_bad][1] == 1 and symm_hashmap[key] == 0)):\n",
    "            # base i symm su jednako zaključili\n",
    "            a += 1\n",
    "        #else:\n",
    "            # oba klasifikatora nisu zaključili jednako\n",
    "            #print(\"\\n------------------------\\nTestni dobar primjer:\\n\", good_test.iloc[i,:].values, \n",
    "                  #\"\\nBase classificator zaključio je da je ovaj primjer: \", base_hashmap[hash_good][1])\n",
    "            #print(\"\\nTestni loš primjer:\\n\", bad_test.iloc[j,:].values,\n",
    "                  #\"\\nBase classificator zaključio je da je ovaj primjer: \", base_hashmap[hash_bad][1])\n",
    "            #print(\"Symmetric classificator zaključio je da je prvi primjer dobar, a drugi loš: \",symm_hashmap[key])\n",
    "        \n",
    "        if((lrcv_hashmap[hash_good][1] == 1 and lrcv_hashmap[hash_bad][1] == 0 and symm_hashmap[key] == 1)\n",
    "          or (lrcv_hashmap[hash_good][1] == 0 and lrcv_hashmap[hash_bad][1] == 1 and symm_hashmap[key] == 0)):\n",
    "            # lrcv i symm su jednako zaključili\n",
    "            b += 1\n",
    "        #else:\n",
    "            # oba klasifikatora nisu zaključili jednako\n",
    "            #print(\"\\n------------------------\\nTestni dobar primjer:\\n\", good_test.iloc[i,:].values, \n",
    "                  #\"\\nLRCV classificator zaključio je da je ovaj primjer: \", lrcv_hashmap[hash_good][1])\n",
    "            #print(\"\\nTestni loš primjer:\\n\", bad_test.iloc[j,:].values,\n",
    "                  #\"\\nLRCV classificator zaključio je da je ovaj primjer: \", lrcv_hashmap[hash_bad][1])\n",
    "            #print(\"Symmetric classificator zaključio je da je prvi primjer dobar, a drugi loš: \",symm_hashmap[key])\n",
    "        \n",
    "print(\"Ukupno preklapanje u procjenama base i symmetric klasifikatora je: \", a/N)\n",
    "print(\"Ukupno preklapanje u procjenama log.reg. CV i symmetric klasifikatora je: \", b/N)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
