{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import operator, functools, time, itertools\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, Imputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import hashlib, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (3000, 24)\n",
      "Default rate:\n",
      " 0    2332\n",
      "1     668\n",
      "Name: default.payment.next.month, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.136720</td>\n",
       "      <td>0.810161</td>\n",
       "      <td>0.185828</td>\n",
       "      <td>-1.057295</td>\n",
       "      <td>-1.246020</td>\n",
       "      <td>1.794564</td>\n",
       "      <td>1.782348</td>\n",
       "      <td>-0.696663</td>\n",
       "      <td>-0.666599</td>\n",
       "      <td>-1.530046</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.672497</td>\n",
       "      <td>-0.663059</td>\n",
       "      <td>-0.652724</td>\n",
       "      <td>-0.341942</td>\n",
       "      <td>-0.227086</td>\n",
       "      <td>-0.296801</td>\n",
       "      <td>-0.308063</td>\n",
       "      <td>-0.314136</td>\n",
       "      <td>-0.293382</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.365981</td>\n",
       "      <td>0.810161</td>\n",
       "      <td>0.185828</td>\n",
       "      <td>0.858557</td>\n",
       "      <td>-1.029047</td>\n",
       "      <td>-0.874991</td>\n",
       "      <td>1.782348</td>\n",
       "      <td>0.138865</td>\n",
       "      <td>0.188746</td>\n",
       "      <td>0.234917</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.621636</td>\n",
       "      <td>-0.606229</td>\n",
       "      <td>-0.597966</td>\n",
       "      <td>-0.341942</td>\n",
       "      <td>-0.213588</td>\n",
       "      <td>-0.240005</td>\n",
       "      <td>-0.244230</td>\n",
       "      <td>-0.314136</td>\n",
       "      <td>-0.180878</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.597202</td>\n",
       "      <td>0.810161</td>\n",
       "      <td>0.185828</td>\n",
       "      <td>0.858557</td>\n",
       "      <td>-0.161156</td>\n",
       "      <td>0.014861</td>\n",
       "      <td>0.111736</td>\n",
       "      <td>0.138865</td>\n",
       "      <td>0.188746</td>\n",
       "      <td>0.234917</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.449730</td>\n",
       "      <td>-0.417188</td>\n",
       "      <td>-0.391630</td>\n",
       "      <td>-0.250292</td>\n",
       "      <td>-0.191887</td>\n",
       "      <td>-0.240005</td>\n",
       "      <td>-0.244230</td>\n",
       "      <td>-0.248683</td>\n",
       "      <td>-0.012122</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.905498</td>\n",
       "      <td>0.810161</td>\n",
       "      <td>0.185828</td>\n",
       "      <td>-1.057295</td>\n",
       "      <td>0.164303</td>\n",
       "      <td>0.014861</td>\n",
       "      <td>0.111736</td>\n",
       "      <td>0.138865</td>\n",
       "      <td>0.188746</td>\n",
       "      <td>0.234917</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232373</td>\n",
       "      <td>-0.186729</td>\n",
       "      <td>-0.156579</td>\n",
       "      <td>-0.221191</td>\n",
       "      <td>-0.169361</td>\n",
       "      <td>-0.228645</td>\n",
       "      <td>-0.237846</td>\n",
       "      <td>-0.244166</td>\n",
       "      <td>-0.237130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.905498</td>\n",
       "      <td>-1.234323</td>\n",
       "      <td>0.185828</td>\n",
       "      <td>-1.057295</td>\n",
       "      <td>2.334029</td>\n",
       "      <td>-0.874991</td>\n",
       "      <td>0.111736</td>\n",
       "      <td>-0.696663</td>\n",
       "      <td>0.188746</td>\n",
       "      <td>0.234917</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.346997</td>\n",
       "      <td>-0.348137</td>\n",
       "      <td>-0.331482</td>\n",
       "      <td>-0.221191</td>\n",
       "      <td>1.335034</td>\n",
       "      <td>0.271165</td>\n",
       "      <td>0.266434</td>\n",
       "      <td>-0.269039</td>\n",
       "      <td>-0.255187</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL       SEX  EDUCATION  MARRIAGE       AGE     PAY_0     PAY_2  \\\n",
       "0  -1.136720  0.810161   0.185828 -1.057295 -1.246020  1.794564  1.782348   \n",
       "1  -0.365981  0.810161   0.185828  0.858557 -1.029047 -0.874991  1.782348   \n",
       "2  -0.597202  0.810161   0.185828  0.858557 -0.161156  0.014861  0.111736   \n",
       "3  -0.905498  0.810161   0.185828 -1.057295  0.164303  0.014861  0.111736   \n",
       "4  -0.905498 -1.234323   0.185828 -1.057295  2.334029 -0.874991  0.111736   \n",
       "\n",
       "      PAY_3     PAY_4     PAY_5             ...              BILL_AMT4  \\\n",
       "0 -0.696663 -0.666599 -1.530046             ...              -0.672497   \n",
       "1  0.138865  0.188746  0.234917             ...              -0.621636   \n",
       "2  0.138865  0.188746  0.234917             ...              -0.449730   \n",
       "3  0.138865  0.188746  0.234917             ...              -0.232373   \n",
       "4 -0.696663  0.188746  0.234917             ...              -0.346997   \n",
       "\n",
       "   BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  \\\n",
       "0  -0.663059  -0.652724 -0.341942 -0.227086 -0.296801 -0.308063 -0.314136   \n",
       "1  -0.606229  -0.597966 -0.341942 -0.213588 -0.240005 -0.244230 -0.314136   \n",
       "2  -0.417188  -0.391630 -0.250292 -0.191887 -0.240005 -0.244230 -0.248683   \n",
       "3  -0.186729  -0.156579 -0.221191 -0.169361 -0.228645 -0.237846 -0.244166   \n",
       "4  -0.348137  -0.331482 -0.221191  1.335034  0.271165  0.266434 -0.269039   \n",
       "\n",
       "   PAY_AMT6  default.payment.next.month  \n",
       "0 -0.293382                           1  \n",
       "1 -0.180878                           1  \n",
       "2 -0.012122                           0  \n",
       "3 -0.237130                           0  \n",
       "4 -0.255187                           0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def credit_dataset():\n",
    "    dataset = pd.read_csv(\"data\\\\UCI_Credit_Card.csv\")\n",
    "    del dataset['ID']\n",
    "\n",
    "    need_scaling = list(filter(functools.partial(operator.ne, 'default.payment.next.month'), dataset.columns.tolist()))\n",
    "    scaler = StandardScaler()\n",
    "    for feature in need_scaling:\n",
    "        dataset[feature] = scaler.fit_transform(dataset[feature].values.reshape(-1,1))\n",
    "            \n",
    "    return dataset\n",
    "\n",
    "dataset = credit_dataset()[:3000]\n",
    "print(\"Dataset shape:\", dataset.shape)\n",
    "print(\"Default rate:\\n\", dataset[\"default.payment.next.month\"].value_counts())\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset_good shape: (2332, 23)\n",
      "Dataset_bad shape: (668, 23)\n",
      "Non-default rate: 0.7853333333333333\n",
      "Default rate: 0.21466666666666667\n"
     ]
    }
   ],
   "source": [
    "dataset_good = dataset[dataset['default.payment.next.month'] == 0]\n",
    "dataset_bad = dataset[dataset['default.payment.next.month'] == 1]\n",
    "del dataset_good['default.payment.next.month']\n",
    "del dataset_bad['default.payment.next.month']\n",
    "print(\"Dataset_good shape:\", dataset_good.shape)\n",
    "print(\"Dataset_bad shape:\", dataset_bad.shape)\n",
    "\n",
    "#good_rate = 23364/30000\n",
    "#bad_rate = 6636/30000\n",
    "good_rate = 1178/1500\n",
    "bad_rate = 322/1500\n",
    "print(\"Non-default rate:\", good_rate)\n",
    "print(\"Default rate:\", bad_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratificirana podjela - provjera koliko je potrebno \"dobrih\" i \"loših\" primjera u train i test setu. Sampliranje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dimensions for symmetric classifier:\n",
      "(1865, 23) (467, 23) (534, 23) (134, 23)\n",
      "\n",
      "Dimensions for base classifier:\n",
      "(2399, 23) (2399, 1) (601, 23) (601, 1)\n"
     ]
    }
   ],
   "source": [
    "train_size = 30000 * 0.8\n",
    "test_size = 30000 * 0.2\n",
    "#print(\"Number of good clients for train:\", round(train_size*good_rate))\n",
    "#print(\"Number of bad clients for train:\", round(train_size*bad_rate))\n",
    "#print(\"\\nNumber of good clients for test:\", round(test_size*good_rate))\n",
    "#print(\"Number of bad clients for test:\", round(test_size*bad_rate))\n",
    "\n",
    "good_train, good_test = train_test_split(dataset_good, test_size=0.2)\n",
    "bad_train, bad_test = train_test_split(dataset_bad, test_size=0.2)\n",
    "print(\"\\nDimensions for symmetric classifier:\")\n",
    "print(good_train.shape, good_test.shape, bad_train.shape, bad_test.shape)\n",
    "\n",
    "y_train = np.array([1]*len(good_train) + [0]*len(bad_train)).reshape(-1,1)\n",
    "x_train = good_train.append(bad_train)\n",
    "x_train['default.payment.next.month'] = y_train\n",
    "x_train = shuffle(x_train)\n",
    "y_train = x_train['default.payment.next.month'].reshape(-1,1)\n",
    "del x_train['default.payment.next.month']\n",
    "\n",
    "y_test = np.array([1]*len(good_test) + [0]*len(bad_test)).reshape(-1,1)\n",
    "x_test = good_test.append(bad_test)\n",
    "x_test['default.payment.next.month'] = y_test\n",
    "x_test = shuffle(x_test)\n",
    "y_test = x_test['default.payment.next.month'].reshape(-1,1)\n",
    "del x_test['default.payment.next.month']\n",
    "\n",
    "print(\"\\nDimensions for base classifier:\")\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def small_network(input_placeholder):\n",
    "    layer_1 = tf.layers.dense(input_placeholder, 70, tf.nn.relu, name=\"layer_1\", reuse=tf.AUTO_REUSE)\n",
    "    layer_2 = tf.layers.dense(layer_1, 60, tf.nn.relu, name=\"layer_2\", reuse=tf.AUTO_REUSE)\n",
    "    layer_3 = tf.layers.dense(layer_2, 40, tf.nn.relu, name=\"layer_3\", reuse=tf.AUTO_REUSE)\n",
    "    layer_4 = tf.layers.dense(layer_3, 30, tf.nn.relu, name=\"layer_4\", reuse=tf.AUTO_REUSE)\n",
    "    layer_5 = tf.layers.dense(layer_4, 15, tf.nn.relu, name=\"layer_5\", reuse=tf.AUTO_REUSE)\n",
    "    output = tf.layers.dense(layer_5, 1, name=\"output\", reuse=tf.AUTO_REUSE)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y_out, y_test, symm):\n",
    "    y_out = [o >= 0.5 for o in y_out]\n",
    "    sd = [1 if o else -1 for o in y_out]\n",
    "    \n",
    "    print('\\nAccuracy score = ', accuracy_score(y_test, y_out))\n",
    "    if not symm:\n",
    "        print('Precision score = ', precision_score(y_test, y_out))\n",
    "        print('F1 score = ', f1_score(y_test, y_out))\n",
    "    print('Recall score = ', recall_score(y_test, y_out))\n",
    "    if symm:\n",
    "        print('Somers\\' D = ', sum(sd)/len(sd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "input_ = tf.placeholder(tf.float32, shape=[None, x_train.shape[1]])\n",
    "output = tf.placeholder(tf.float32, shape=[None,1])\n",
    "\n",
    "logit = small_network(input_)\n",
    "h = tf.sigmoid(logit)\n",
    "\n",
    "loss = tf.losses.sigmoid_cross_entropy(output, logit)\n",
    "lr = tf.placeholder(tf.float32, shape=[])\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=lr, beta1=0.9, beta2=0.999).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_hashmap = {}\n",
    "\n",
    "def base_classification(data, y, l_r, num_epochs, bsize, if_test):\n",
    "    num_batches = len(data) // bsize\n",
    "    residue = len(data) % bsize\n",
    "    if residue != 0:\n",
    "        num_batches += 1\n",
    "        \n",
    "    losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        h_out = []\n",
    "        #start = time.time()\n",
    "        for batch in range(num_batches):\n",
    "            i = batch * bsize\n",
    "            j = (batch + 1) * bsize\n",
    "            if(residue != 0 and batch + 1 == num_batches):\n",
    "                j = i + residue\n",
    "\n",
    "            loss_, h_, _ = sess.run([loss, h, train_op],feed_dict={input_: data.iloc[i:j,:],output: y[i:j],lr:l_r})\n",
    "            h_out.extend([hh[0] for hh in h_])\n",
    "            total_loss += loss_\n",
    "            \n",
    "            if(if_test):\n",
    "                for k in range(i,j):\n",
    "                    x = data.iloc[k,:]\n",
    "                    key = hashlib.sha256(x.values.tobytes()).hexdigest()\n",
    "                    base_hashmap[key] = tuple((x, round(h_out[k])))\n",
    "\n",
    "        losses.append(total_loss / num_batches)\n",
    "        #print(\"Epoch {} / {}, Loss = {}\".format(epoch + 1, num_epochs, total_loss / num_batches))\n",
    "        #print(time.time()-start)\n",
    "        \n",
    "    return h_out, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "Accuracy score =  0.9970821175489787\n",
      "Precision score =  0.9978563772775991\n",
      "F1 score =  0.9981238273921201\n",
      "Recall score =  0.9983914209115281\n",
      "\n",
      "Testing...\n",
      "\n",
      "Accuracy score =  0.7371048252911814\n",
      "Precision score =  0.8108651911468813\n",
      "F1 score =  0.8360995850622406\n",
      "Recall score =  0.8629550321199143\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    base_train_out, losses = base_classification(x_train, y_train, 0.001, 1000, 50, False)\n",
    "    metrics(base_train_out, y_train, False)\n",
    "    \n",
    "    print(\"\\nTesting...\")\n",
    "    base_test_out, losses = base_classification(x_test, y_test, 0.001, 1, 50, True) \n",
    "    metrics(base_test_out, y_test, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symmetric classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "num_features = good_train.shape[1]\n",
    "\n",
    "input_left = tf.placeholder(tf.float32, shape=[None, num_features*2])\n",
    "input_right = tf.concat([input_left[:, num_features:], input_left[:, :num_features]], axis=1)\n",
    "output = tf.placeholder(tf.float32, shape=[None,1])\n",
    "\n",
    "f_left = small_network(input_left)\n",
    "f_right = small_network(input_right)\n",
    "logit = f_left - f_right\n",
    "\n",
    "h = tf.sigmoid(logit)\n",
    "\n",
    "loss = tf.losses.sigmoid_cross_entropy(output, logit)\n",
    "lr = tf.placeholder(tf.float32, shape=[])\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=lr, beta1=0.9, beta2=0.999).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "symm_hashmap = {}\n",
    "\n",
    "def symmetric_classification(good_data, bad_data, l_r, num_epochs, if_test):\n",
    "    losses = []\n",
    "    y = np.empty((len(bad_data) * len(good_data), 1), int)\n",
    "    y.fill(1)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        good_data = shuffle(good_data)\n",
    "        bad_data = shuffle(bad_data)\n",
    "        h_out = []\n",
    "        \n",
    "        conc = np.concatenate\n",
    "            \n",
    "        for i in range(len(good_data)):\n",
    "            \n",
    "            minibatch = []\n",
    "            append = minibatch.append\n",
    "            y_ = np.empty((len(bad_data), 1), int)\n",
    "            y_.fill(1.)\n",
    "            \n",
    "            g = good_data.iloc[i,:].reshape(1,-1)\n",
    "            \n",
    "            for j in range(len(bad_data)):\n",
    "                b = bad_data.iloc[j,:].reshape(1,-1)\n",
    "                append(conc((g, b), axis=None))\n",
    "            \n",
    "                if(if_test):\n",
    "                    hash_good = hashlib.sha256(g.tobytes()).hexdigest()\n",
    "                    hash_bad = hashlib.sha256(b.tobytes()).hexdigest()\n",
    "                    key = tuple((hash_good, hash_bad))\n",
    "                    symm_hashmap[key] = 1\n",
    "           \n",
    "            loss_, h_, _ = sess.run([loss, h, train_op], feed_dict={input_left: minibatch, output: y_, lr: l_r})\n",
    "            h_out.extend([hh[0] for hh in h_])\n",
    "            total_loss += loss_\n",
    "\n",
    "        losses.append(total_loss / len(bad_data))\n",
    "        print(\"Epoch {} / {}, Loss = {}\".format(epoch + 1, num_epochs, total_loss / len(bad_data)))\n",
    "        \n",
    "    return h_out, y, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 1 / 15, Loss = 2.164525905866455\n",
      "Epoch 2 / 15, Loss = 1.9291914075914742\n",
      "Epoch 3 / 15, Loss = 1.8895121455639043\n",
      "Epoch 4 / 15, Loss = 1.8392951225352645\n",
      "Epoch 5 / 15, Loss = 1.7289808063387648\n",
      "Epoch 6 / 15, Loss = 1.6016621366840846\n",
      "Epoch 7 / 15, Loss = 1.549893219833182\n",
      "Epoch 8 / 15, Loss = 1.3913937418160032\n",
      "Epoch 9 / 15, Loss = 1.4766081207962043\n",
      "Epoch 10 / 15, Loss = 1.2612126937235464\n",
      "Epoch 11 / 15, Loss = 1.2229915056334049\n",
      "Epoch 12 / 15, Loss = 1.0634873380949057\n",
      "Epoch 13 / 15, Loss = 1.1019375836882175\n",
      "Epoch 14 / 15, Loss = 0.965566523130704\n",
      "Epoch 15 / 15, Loss = 0.8963902150747307\n",
      "\n",
      "Accuracy score =  0.9241337068610618\n",
      "Recall score =  0.9241337068610618\n",
      "Somers' D =  0.8482674137221234\n",
      "\n",
      "Testing...\n",
      "Epoch 1 / 1, Loss = 1.661131215420788\n",
      "\n",
      "Accuracy score =  0.8449455080060085\n",
      "Recall score =  0.8449455080060085\n",
      "Somers' D =  0.689891016012017\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    symm_train_out, y, losses = symmetric_classification(good_train, bad_train, 0.01, 20, False)\n",
    "    metrics(symm_train_out, y, True)\n",
    "    \n",
    "    print(\"\\nTesting...\")\n",
    "    symm_test_out, y, losses = symmetric_classification(good_test, bad_test, 0.01, 1, True)\n",
    "    metrics(symm_test_out, y, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base & symmetric classification comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukupno preklapanje u procjenama klasifikatora je:  0.2575985170507207\n"
     ]
    }
   ],
   "source": [
    "N = len(good_test) * len(bad_test)\n",
    "a = 0\n",
    "b = 0\n",
    "\n",
    "for i in range(len(good_test)):\n",
    "    for j in range(len(bad_test)):\n",
    "        hash_good = hashlib.sha256(good_test.iloc[i,:].values.tobytes()).hexdigest()\n",
    "        hash_bad = hashlib.sha256(bad_test.iloc[j,:].values.tobytes()).hexdigest()\n",
    "        key = (hash_good, hash_bad)\n",
    "        if((base_hashmap[hash_good][1] == 1 and base_hashmap[hash_bad][1] == 0 and symm_hashmap[key] == 1)\n",
    "          or (base_hashmap[hash_good][1] == 0 and base_hashmap[hash_bad][1] == 1 and symm_hashmap[key] == 0)):\n",
    "            # oba klasifikatora su jednako zaključila\n",
    "            a += 1\n",
    "        else:\n",
    "            b += 1\n",
    "            # oba klasifikatora nisu zaključila jednako\n",
    "            #print(\"\\n------------------------\\nTestni dobar primjer:\\n\", good_test.iloc[i,:].values, \n",
    "                  #\"\\nBase classificator zaključio je da je ovaj primjer: \", base_hashmap[hash_good][1])\n",
    "            #print(\"\\nTestni loš primjer:\\n\", bad_test.iloc[j,:].values,\n",
    "                  #\"\\nBase classificator zaključio je da je ovaj primjer: \", base_hashmap[hash_bad][1])\n",
    "            #print(\"Symmetric classificator zaključio je da je prvi primjer dobar, a drugi loš: \",symm_hashmap[key])\n",
    "\n",
    "print(\"Ukupno preklapanje u procjenama klasifikatora je: \", a/N)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
